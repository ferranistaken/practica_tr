{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "import cv2\n",
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.applications\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16\n",
    "import keras\n",
    "from tensorflow.keras.utils import serialize_keras_object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(): \n",
    "    input_layer = Input(shape=(120,120,3))\n",
    "    \n",
    "    vgg = VGG16(include_top=False)(input_layer)\n",
    "    #Model de classificació\n",
    "    f1 = GlobalMaxPooling2D()(vgg)\n",
    "    class1 = Dense(2048, activation='relu')(f1) #relu == funció que determina la classe; \n",
    "    class2 = Dense(3, activation='sigmoid')(class1) # sigmoid == funció que determina la presició de la classe\n",
    "\n",
    "    # sigmoid = f(x) = 1/(1+e^-x)\n",
    "    \n",
    "    #Model de localització de coordenades\n",
    "    f2 = GlobalMaxPooling2D()(vgg)\n",
    "    regress1 = Dense(2048, activation='relu')(f2)\n",
    "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
    "    \n",
    "    detector = Model(inputs=input_layer, outputs=[class2, regress2])\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001) #li introduïm el decay que hem calculat a l'optimitzador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, yhat):#primer valor: coordenades reals, segon valor: coordenades previstes     \n",
    "    y_true = tf.reshape(y_true, (5, 4))\n",
    "    \n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2])) #diferència dels dos primers valors de cada fila de la matriu\n",
    "                  \n",
    "    h_true = y_true[:,3] - y_true[:,1] #quarta columna d'una matriu - segona columna\n",
    "    w_true = y_true[:,2] - y_true[:,0] #tercera columna - primera\n",
    "\n",
    "    h_pred = yhat[:,3] - yhat[:,1] \n",
    "    w_pred = yhat[:,2] - yhat[:,0] \n",
    "    '''\n",
    "    delta_size = suma dels quadrats de les diferències entre les dimensions originals \n",
    "    i les dimensions reconstruïdes de l'imatge.\n",
    "    '''\n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss = tf.keras.losses.CategoricalCrossentropy() #model que fa una classificació binaria \n",
    "regressloss = localization_loss #model que acabem de crear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector(Model):\n",
    "    def __init__(self, fruita, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.base_model = fruita\n",
    "\n",
    "    def compile(self, opt, classloss, localizationloss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.closs = classloss\n",
    "        self.lloss = localizationloss\n",
    "        self.opt = opt\n",
    "\n",
    "    def train_step(self, batch, **kwargs):\n",
    "        X, y = batch\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            classes, coords = self.base_model(X, training=True)\n",
    "            batch_classloss = self.closs(tf.reshape(y[0], (5, 3)), classes)\n",
    "            batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "\n",
    "            total_loss = batch_localizationloss + 0.5 * batch_classloss\n",
    "\n",
    "        grad = tape.gradient(total_loss, self.base_model.trainable_variables)\n",
    "        self.opt.apply_gradients(zip(grad, self.base_model.trainable_variables))\n",
    "\n",
    "        return {\"total_loss\": total_loss, \"class_loss\": batch_classloss, \"regress_loss\": batch_localizationloss}\n",
    "\n",
    "    def test_step(self, batch, **kwargs):\n",
    "        X, y = batch\n",
    "\n",
    "        classes, coords = self.base_model(X, training=False)\n",
    "\n",
    "        batch_classloss = self.closs(tf.reshape(y[0], (5, 3)), classes)\n",
    "        batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "        total_loss = batch_localizationloss + 0.5 * batch_classloss\n",
    "\n",
    "        return {\"total_loss\": total_loss, \"class_loss\": batch_classloss, \"regress_loss\": batch_localizationloss}\n",
    "\n",
    "    def call(self, X, **kwargs):\n",
    "        return self.base_model(X, **kwargs)\n",
    "    \n",
    "    def get_config(self):\n",
    "        # Get the base configuration\n",
    "        base_config = super().get_config()\n",
    "        \n",
    "        # Serialize the \"fruita\" model and store it in the configuration\n",
    "        fruita_config = serialize_keras_object(self.base_model)\n",
    "        \n",
    "        # Construct the complete configuration dictionary\n",
    "        config = {\n",
    "            \"fruita\": fruita_config,\n",
    "        }\n",
    "        \n",
    "        # Merge the base configuration and the custom configuration\n",
    "        return {**base_config, **config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Detector(detector)\n",
    "model.build(input_shape=(5, 120, 120, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('detector_fruites_weights.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unexpected exception formatting exception. Falling back to standard exception\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\odena\\AppData\\Local\\Temp\\ipykernel_9240\\1322708144.py\", line 17, in <module>\n",
      "    yhat = Detector.predict(tf.expand_dims(resized, axis=0), batch_size=5)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"t:\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 70, in error_handler\n",
      "    raise e.with_traceback(filtered_tb) from None\n",
      "  File \"t:\\env\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py\", line 67, in error_handler\n",
      "    filtered_tb = _process_traceback_frames(e.__traceback__)\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "TypeError: Model.predict() missing 1 required positional argument: 'x'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2105, in showtraceback\n",
      "    stb = self.InteractiveTB.structured_traceback(\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"t:\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1396, in structured_traceback\n",
      "    return FormattedTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"t:\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1287, in structured_traceback\n",
      "    return VerboseTB.structured_traceback(\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"t:\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1140, in structured_traceback\n",
      "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
      "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"t:\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1030, in format_exception_as_a_whole\n",
      "    self.get_records(etb, number_of_lines_of_context, tb_offset) if etb else []\n",
      "    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"t:\\env\\Lib\\site-packages\\IPython\\core\\ultratb.py\", line 1127, in get_records\n",
      "    res = list(stack_data.FrameInfo.stack_data(etb, options=options))[tb_offset:]\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"t:\\env\\Lib\\site-packages\\stack_data\\core.py\", line 597, in stack_data\n",
      "    yield from collapse_repeated(\n",
      "  File \"t:\\env\\Lib\\site-packages\\stack_data\\utils.py\", line 83, in collapse_repeated\n",
      "    yield from map(mapper, original_group)\n",
      "  File \"t:\\env\\Lib\\site-packages\\stack_data\\core.py\", line 587, in mapper\n",
      "    return cls(f, options)\n",
      "           ^^^^^^^^^^^^^^^\n",
      "  File \"t:\\env\\Lib\\site-packages\\stack_data\\core.py\", line 551, in __init__\n",
      "    self.executing = Source.executing(frame_or_tb)\n",
      "                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"t:\\env\\Lib\\site-packages\\executing\\executing.py\", line 378, in executing\n",
      "    assert_(new_stmts <= stmts)\n",
      "  File \"t:\\env\\Lib\\site-packages\\executing\\executing.py\", line 154, in assert_\n",
      "    raise AssertionError(str(message))\n",
      "AssertionError\n"
     ]
    }
   ],
   "source": [
    "# Load your Detector model here\n",
    "# Open the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if not ret:\n",
    "        break\n",
    "    \n",
    "    frame = frame[50:500, 50:500, :]\n",
    "    \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    target_size = tf.constant([120, 120], dtype=tf.int32)\n",
    "    resized = tf.image.resize(rgb, target_size)\n",
    "\n",
    "    yhat = Detector.predict(tf.expand_dims(resized, axis=0), batch_size=5)\n",
    "    sample_coords = yhat[0]  # Assuming yhat contains the coordinates and class probabilities\n",
    "    \n",
    "    if yhat[0] > 0.5:\n",
    "        # Controls the main rectangle\n",
    "        cv2.rectangle(frame,\n",
    "                      tuple(np.multiply(sample_coords[:2], [450, 450]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [450, 450]).astype(int)),\n",
    "                      (255, 0, 0), 2)\n",
    "        \n",
    "        # Controls the label rectangle\n",
    "        label_position = (\n",
    "            int(np.multiply(sample_coords[0], 450)),\n",
    "            int(np.multiply(sample_coords[1], 450)) - 30\n",
    "        )\n",
    "        cv2.rectangle(frame, label_position, (label_position[0] + 80, label_position[1] + 30), (255, 0, 0), -1)\n",
    "\n",
    "        # Determine the fruit label based on class probabilities\n",
    "        fruit_labels = ['poma', 'pera', 'mandarina', 'no ho tinc clar']\n",
    "        max_prob_index = np.argmax(yhat[1])\n",
    "        \n",
    "        if yhat[1][0][max_prob_index] > 0.7:\n",
    "            cv2.putText(frame, fruit_labels[max_prob_index], label_position,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2, cv2.LINE_AA)\n",
    "        else:\n",
    "            cv2.putText(frame, 'no ho tinc clar', label_position,\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2, cv2.LINE_AA)\n",
    "\n",
    "    cv2.imshow('EyeTrack', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
