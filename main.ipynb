{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7652d352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: labelme in d:\\tr_practica\\env\\lib\\site-packages (5.2.1)\n",
      "Requirement already satisfied: tensorflow in d:\\tr_practica\\env\\lib\\site-packages (2.12.0)\n",
      "Collecting tensorflow-gpu\n",
      "  Using cached tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting opencv-python\n",
      "  Using cached opencv_python-4.8.0.76-cp37-abi3-win_amd64.whl (38.1 MB)\n",
      "Requirement already satisfied: matplotlib in d:\\tr_practica\\env\\lib\\site-packages (3.7.1)\n",
      "Requirement already satisfied: albumentations in d:\\tr_practica\\env\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: imgviz>=0.11 in d:\\tr_practica\\env\\lib\\site-packages (from labelme) (1.7.2)\n",
      "Requirement already satisfied: natsort>=7.1.0 in d:\\tr_practica\\env\\lib\\site-packages (from labelme) (8.3.1)\n",
      "Requirement already satisfied: numpy in d:\\tr_practica\\env\\lib\\site-packages (from labelme) (1.23.5)\n",
      "Requirement already satisfied: Pillow>=2.8 in d:\\tr_practica\\env\\lib\\site-packages (from labelme) (9.5.0)\n",
      "Requirement already satisfied: PyYAML in d:\\tr_practica\\env\\lib\\site-packages (from labelme) (6.0)\n",
      "Requirement already satisfied: qtpy!=1.11.2 in d:\\tr_practica\\env\\lib\\site-packages (from labelme) (2.3.1)\n",
      "Requirement already satisfied: termcolor in d:\\tr_practica\\env\\lib\\site-packages (from labelme) (2.3.0)\n",
      "Requirement already satisfied: colorama in d:\\tr_practica\\env\\lib\\site-packages (from labelme) (0.4.6)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.4.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.5.9)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.8.0)\n",
      "Requirement already satisfied: jax>=0.3.15 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.10)\n",
      "Requirement already satisfied: libclang>=13.0.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (16.0.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.3.0)\n",
      "Requirement already satisfied: packaging in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (23.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.23.1)\n",
      "Requirement already satisfied: setuptools in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (65.5.0)\n",
      "Requirement already satisfied: six>=1.12.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.6.0)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.55.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: python_version>\"3.7\" in d:\\tr_practica\\env\\lib\\site-packages (from tensorflow-gpu) (0.0.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in d:\\tr_practica\\env\\lib\\site-packages (from matplotlib) (1.0.7)\n",
      "Requirement already satisfied: cycler>=0.10 in d:\\tr_practica\\env\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in d:\\tr_practica\\env\\lib\\site-packages (from matplotlib) (4.39.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\tr_practica\\env\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in d:\\tr_practica\\env\\lib\\site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in d:\\tr_practica\\env\\lib\\site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: scipy in d:\\tr_practica\\env\\lib\\site-packages (from albumentations) (1.10.1)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in d:\\tr_practica\\env\\lib\\site-packages (from albumentations) (0.20.0)\n",
      "Requirement already satisfied: qudida>=0.0.4 in d:\\tr_practica\\env\\lib\\site-packages (from albumentations) (0.0.4)\n",
      "Requirement already satisfied: opencv-python-headless>=4.1.1 in d:\\tr_practica\\env\\lib\\site-packages (from albumentations) (4.7.0.72)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in d:\\tr_practica\\env\\lib\\site-packages (from qudida>=0.0.4->albumentations) (1.2.2)\n",
      "Requirement already satisfied: networkx>=2.8 in d:\\tr_practica\\env\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (3.1)\n",
      "Requirement already satisfied: imageio>=2.4.1 in d:\\tr_practica\\env\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2.28.1)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in d:\\tr_practica\\env\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (2023.4.12)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in d:\\tr_practica\\env\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: lazy_loader>=0.1 in d:\\tr_practica\\env\\lib\\site-packages (from scikit-image>=0.16.1->albumentations) (0.2)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in d:\\tr_practica\\env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.40.0)\n",
      "Requirement already satisfied: ml-dtypes>=0.1.0 in d:\\tr_practica\\env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.1.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in d:\\tr_practica\\env\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\tr_practica\\env\\lib\\site-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in d:\\tr_practica\\env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.18.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in d:\\tr_practica\\env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in d:\\tr_practica\\env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.31.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in d:\\tr_practica\\env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in d:\\tr_practica\\env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.3.4)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\tr_practica\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.3.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\tr_practica\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.3.0)\n",
      "Requirement already satisfied: urllib3<2.0 in d:\\tr_practica\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.26.16)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\tr_practica\\env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in d:\\tr_practica\\env\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\tr_practica\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in d:\\tr_practica\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in d:\\tr_practica\\env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2023.5.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in d:\\tr_practica\\env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.2)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in d:\\tr_practica\\env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.5.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in d:\\tr_practica\\env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Building wheels for collected packages: tensorflow-gpu\n",
      "  Building wheel for tensorflow-gpu (setup.py): started\n",
      "  Building wheel for tensorflow-gpu (setup.py): finished with status 'error'\n",
      "  Running setup.py clean for tensorflow-gpu\n",
      "Failed to build tensorflow-gpu\n",
      "Installing collected packages: tensorflow-gpu, opencv-python\n",
      "  Running setup.py install for tensorflow-gpu: started\n",
      "  Running setup.py install for tensorflow-gpu: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × python setup.py bdist_wheel did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [18 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\GÃºssem\\AppData\\Local\\Temp\\pip-install-n5bgl_sx\\tensorflow-gpu_9c43ae31c90d40a79f92aa3d775f86d9\\setup.py\", line 37, in <module>\n",
      "          raise Exception(TF_REMOVAL_WARNING)\n",
      "      Exception:\n",
      "      \n",
      "      =========================================================\n",
      "      The \"tensorflow-gpu\" package has been removed!\n",
      "      \n",
      "      Please install \"tensorflow\" instead.\n",
      "      \n",
      "      Other than the name, the two packages have been identical\n",
      "      since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "      information, see: pypi.org/project/tensorflow-gpu\n",
      "      =========================================================\n",
      "      \n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "  ERROR: Failed building wheel for tensorflow-gpu\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for tensorflow-gpu did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [18 lines of output]\n",
      "      Traceback (most recent call last):\n",
      "        File \"<string>\", line 2, in <module>\n",
      "        File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "        File \"C:\\Users\\GÃºssem\\AppData\\Local\\Temp\\pip-install-n5bgl_sx\\tensorflow-gpu_9c43ae31c90d40a79f92aa3d775f86d9\\setup.py\", line 37, in <module>\n",
      "          raise Exception(TF_REMOVAL_WARNING)\n",
      "      Exception:\n",
      "      \n",
      "      =========================================================\n",
      "      The \"tensorflow-gpu\" package has been removed!\n",
      "      \n",
      "      Please install \"tensorflow\" instead.\n",
      "      \n",
      "      Other than the name, the two packages have been identical\n",
      "      since TensorFlow 2.1, or roughly since Sep 2019. For more\n",
      "      information, see: pypi.org/project/tensorflow-gpu\n",
      "      =========================================================\n",
      "      \n",
      "      \n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> tensorflow-gpu\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.2.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install labelme tensorflow tensorflow-gpu opencv-python matplotlib albumentations"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33e0455a",
   "metadata": {},
   "source": [
    "# 1. Obtenció i tractament de dades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578d20b",
   "metadata": {},
   "source": [
    "### 1.1 Ús de la llibreria LabelMe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa979ccf",
   "metadata": {},
   "source": [
    "* Executem la llibreria LabelMe, que manualment ens permetrà obtenir unes coordenades que marquin la àrea del objecte que volem detectar. Aquesta llibreria ens retornarà un arxiu .json amb els valors numèrics dels punts marcats. Amb aquests valors, la xarxa neuronal serà capaç d'entrenar-se. Haurem de crear una carpeta que anomenarem \"labels\" on hi aniran aquestes \"etiquetes\" en format .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aaed57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23d6376c",
   "metadata": {},
   "source": [
    "###  1.2 Creació de la base de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42b8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importació de llibreries necessàries\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ac200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limitació de la memòria GPU \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cc1c98b1",
   "metadata": {},
   "source": [
    "### Carregar les imatges a TF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce224428",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges = tf.data.Dataset.list_files('data\\\\images\\\\*.png') # introduïm les imatges a la base de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_imatge(imatge): #funció per a carregar imatges\n",
    "    byte_img = tf.io.read_file(imatge)\n",
    "    img = tf.io.decode_png(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges = imatges.map(carregar_imatge) # executem la funció per carregar les imatges en la base de dades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges.as_numpy_iterator().next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imatgesDividir(dir_carpeta, n_imatges):\n",
    "    num_elements = len(os.listdir(dir_carpeta))\n",
    "    n_train = round(num_elements*0.7) # 70% de les imatges per entrenar\n",
    "    n_test = round(num_elements*0.15) # 15% de les imatges per provar\n",
    "    n_val = num_elements - (n_train + n_test) # 15% de les imatges per validar\n",
    "\n",
    "    llista = []\n",
    "    for i in range(1, (n_imatges + 1)):\n",
    "        llista.append(i)\n",
    "\n",
    "    if len(os.listdir(os.path.join(dir_carpeta,\"test\"))) < n_test:\n",
    "        for i in range(n_test):\n",
    "            n = random.choice(llista)\n",
    "            nomt = str(str(n) + \".jpg\")\n",
    "            shutil.move(nomt, os.path.join(dir_carpeta,\"test\"))\n",
    "            llista.remove(n)\n",
    "\n",
    "    if len(os.listdir(os.path.join(dir_carpeta,\"val\"))) < n_val:\n",
    "        for i in range(n_val):\n",
    "            n = random.choice(llista)\n",
    "            nomv = str(str(n) + \".jpg\")\n",
    "            shutil.move(nomv, os.path.join(dir_carpeta,\"val\"))\n",
    "            llista.remove(n)\n",
    "\n",
    "    if len(os.listdir(os.path.join(dir_carpeta,\"val\"))) >= n_val and len(os.listdir(os.path.join(dir_carpeta,\"test\"))) >= n_test: \n",
    "        for i in llista:\n",
    "            nom = str(i) + \".jpg\"\n",
    "            shutil.move(os.path.join(dir_carpeta, nom), os.path.join(dir_carpeta, \"train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la carpeta principal\n",
    "os.mkdir(\"dades\")\n",
    "\n",
    "# Crear les subcarpetes dins de la carpeta principal\n",
    "for subcarpeta in [\"train\", \"test\", \"val\"]:\n",
    "    path_subcarpeta = os.path.join(\"dades\", subcarpeta)\n",
    "    os.mkdir(path_subcarpeta)\n",
    "\n",
    "imatgesDividir('T:\\REP\\deteccio_prova\\data\\images',300) #divisió de les carpetes i de les imatges"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b439be43",
   "metadata": {},
   "source": [
    "### Partició de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dce6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mou les els labels a les seves respectives carpetes\n",
    "for carpeta in ['train','test','val']:\n",
    "    for arxiu in os.listdir(os.path.join('dades', carpeta, 'imagtes')): #per cada arxiu en cada carpeta\n",
    "        nom_arxiu = arxiu.split('.')[0]+'.json' #extreu el nom de l'arxiu\n",
    "        dir_existent = os.path.join('dades','labels', nom_arxiu)#crea possible direcció\n",
    "        if os.path.exists(dir_existent): #si la possible direcció existeix, desplaça l'arxiu .json corresponent\n",
    "            nova_dir = os.path.join('dades',carpeta,'labels',nom_arxiu)\n",
    "            os.replace(dir_existent, nova_dir)#canviem"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5f70389c",
   "metadata": {},
   "source": [
    "### 1.2.1 Ús de la llibreria Albumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071c1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93969970",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=1024, height=1024),\n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', #format de coords que volem (buscar docs)\n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train','test','val']: \n",
    "    for image in os.listdir(os.path.join('dades', partition, 'imagtes')):\n",
    "        img = cv2.imread(os.path.join('dades', partition, 'imagtes', image))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('dades', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [1024,1024,1024,1024]))\n",
    "            # ^^^ carregar imatges i json ^^^\n",
    "\n",
    "        try: \n",
    "            for x in range(60):# quantitat d'imatges que surten d'una imatge base\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['Maduixa'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'imagtes', f'{image.split(\".\")[0]}.{x}.jpg'),augmented['image'])\n",
    "                \n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "                    '''\n",
    "                     La variable “annotation” és un diccionari que conté informació sobre la imatge i \n",
    "                     la seva anotació. Si el fitxer d'anotació existeix, el codi afegeix la caixa delimitadora\n",
    "                     i la classe corresponent a l'objecte detectat a l'estructura “annotation”. \n",
    "                     Si el fitxer d'anotació no existeix, el codi assigna una caixa delimitadora i \n",
    "                     una classe buida a l'estructura “annotation”.\n",
    "                    '''\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9cf0c55a",
   "metadata": {},
   "source": [
    "### Incloure imatges creades amb Albumentations a la Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obrim les carpetes amb les img a manipular i les carreguem\n",
    "train_images = tf.data.Dataset.list_files('aug_data\\\\train\\\\images\\\\*.jpg',shuffle=False)\n",
    "train_images = train_images.map(carregar_imatge)\n",
    "#Es fa resize de les img i també baixem l'escala de la imatge a 1\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "train_images = train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05456564",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files('aug_data\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
    "test_images = test_images.map(carregar_imatge)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "test_images = test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167107c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = tf.data.Dataset.list_files('aug_data\\\\val\\\\images\\\\*.jpg', shuffle=False)\n",
    "val_images = val_images.map(carregar_imatge)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "val_images = val_images.map(lambda x: x/255)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0900d8c7",
   "metadata": {},
   "source": [
    "### 2.5 Carregar etiquetes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funció que carrega els labels\n",
    "def carregar_labels(x):\n",
    "    with open(x.numpy(), 'r', encoding='utf-8') as f:\n",
    "        label = json.load(f)\n",
    "    return [label['class']],label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f279ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_data\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))#tf_py_function(funció, paràmetres, tipus de retorn) \n",
    "#obre els labels i els aplica la funció carregar_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('aug_data\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('aug_data\\\\val\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "94c9566b",
   "metadata": {},
   "source": [
    "### Combinar etiquetes i imatges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00975b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cal comprovar quantes imatges hi ha en cada carpeta\n",
    "print(\"Train: \" + str(len(train_labels)) + \", Test: \" + str(len(test_labels)) + \", Val: \" + str(len(val_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images, train_labels)) #mètode que junta les imatges amb els labels\n",
    "train = train.shuffle(2000) #posar el número que hi ha apoximat cap amunt, en aquest cas 2000\n",
    "train = train.batch(8)#crear lots de 8\n",
    "train = train.prefetch(4)#redueix la capacitat de procesar per evitar errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "test = test.shuffle(500)\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((val_images, val_labels))\n",
    "val = val.shuffle(500)\n",
    "val = val.batch(8)\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18989ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.as_numpy_iterator().next()[1]\n",
    "'''\n",
    "Amb això visualitzem la manera en què hem codificat i guardat les imatges;\n",
    "Obtindrem això:\n",
    "(array([[n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n]], dtype=uint8),\n",
    " array([[n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n]], dtype=float16))\n",
    "\n",
    "la primera columna ens indica la classe de la imatge, és a dir, l'objecte que hi ha a la imatge\n",
    "la segona columna ens indica la bounding box de la imatge, és a dir, la posició de l'objecte a la imatge\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64bdd4d3",
   "metadata": {},
   "source": [
    "# 2. Preparació de la intel·ligència artificial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1288df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#La línia 2 importa les capes de Input, de convolució 2D, de connexió i de agregació màxima global\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "254f476e",
   "metadata": {},
   "source": [
    "### 2.1 Descarregar i carregar el model VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False) \n",
    "#Marca que les ultimes capes de la xarxa no les utilitzarem perquè afegirem les nostres pròpies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26209fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "La funció crea i retorna un model de xarxa neuronal convolucional per a la detecció dels objectes. \n",
    "El model té dues parts: una per a determinar si una imatge conté algun objecte i una altra per a localitzar la maduixa en la imatge. \n",
    "Al utilitzar VGG16, com que esta pre-entrenada, les característiques del input\n",
    "i les classifica en dues branques que son les dues parts mencionades abans de manera automàtica. \n",
    "'''\n",
    "def build_model(): \n",
    "    input_layer = Input(shape=(250,250,3))\n",
    "    \n",
    "    vgg = VGG16(include_top=False)(input_layer)\n",
    "    #Model de classificació\n",
    "    f1 = GlobalMaxPooling2D()(vgg)\n",
    "    class1 = Dense(2048, activation='relu')(f1) #relu == funció que determina la classe; \n",
    "    class2 = Dense(1, activation='sigmoid')(class1) # sigmoid == funció que determina la presició de la classe\n",
    "\n",
    "    # sigmoid = f(x) = 1/(1+e^-x)\n",
    "    \n",
    "    #Model de localització de coordenades\n",
    "    f2 = GlobalMaxPooling2D()(vgg)\n",
    "    regress1 = Dense(2048, activation='relu')(f2)\n",
    "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
    "    \n",
    "    detector = Model(inputs=input_layer, outputs=[class2, regress2])\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97226aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.as_numpy_iterator().next()[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b84e6fb2",
   "metadata": {},
   "source": [
    "### 3.3 Prova de la xarxa neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dbda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3785c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.summary()\n",
    "'''\n",
    "Aquest fragment dona una descripció resumida de la xarxa que acabem de construir,\n",
    "inclou el nombre de capes, el nombre de paràmetres que ha après durant un entrenament i \n",
    "la forma de les dades que passen entre les capes.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49668c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715392aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, coords = detector.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ead66",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, coords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e82e086",
   "metadata": {},
   "source": [
    "### 2.2 Funcions de pèrdua i optimitzadors\n",
    "Els optimitzadors són algorismes que s’utilitzen per ajustar els pesos d’una xarxa neuronal durant l’entrenament. Els optimitzadors són responsables de minimitzar la funció de pèrdua de la xarxa neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001) #li introduïm el decay que hem calculat a l'optimitzador\n",
    "\n",
    "'''\n",
    "En el context de les xarxes neuronals, un optimitzador és un algorisme\n",
    "que ajuda a ajustar els paràmetres de la xarxa per aconseguir una millor precisió.\n",
    "L'optimitzador Adam és un exemple d'això i ajuda a l'optimitzador a convergir més ràpidament\n",
    "i amb més precisió.\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08bb0627",
   "metadata": {},
   "source": [
    "### Creació de 'Localitzation Loss' i 'Classification Loss'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "400ff5f5",
   "metadata": {},
   "source": [
    "La funció té dos components: la pèrdua de localització i la pèrdua de classificació.\n",
    "La pèrdua de localització mesura la diferència entre les coordenades dels quadres delimitadors \n",
    "predits i les coordenades dels quadres delimitadors reals. La pèrdua de classificació mesura la\n",
    "diferència entre les probabilitats de classe predites i les probabilitats de classe reals. \n",
    "En aquesta funció, només es calcula la pèrdua de localització.\n",
    "\n",
    "La funció té com a entrada dos tensors: y_true i yhat. \n",
    "y_true conté les coordenades dels quadres delimitadors reals i\n",
    "les probabilitats de classe reals per a cada objecte en la imatge d’entrada.\n",
    "yhat conté les coordenades dels quadres delimitadors predits i les\n",
    "probabilitats de classe predites per a cada objecte en la imatge d’entrada.\n",
    "\n",
    "La funció calcula la pèrdua de localització sumant el quadrat de la diferència\n",
    "entre les coordenades dels quadres delimitadors reals i les coordenades dels quadres\n",
    "delimitadors predits. A continuació, calcula la diferència entre l’amplada i l’alçada\n",
    "dels quadres delimitadors reals i els quadres delimitadors predits i suma els quadrats\n",
    "d’aquestes diferències. Finalment, retorna la suma de les dues pèrdues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0159efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, yhat):#primer valor: coordenades reals, segon valor: coordenades previstes     \n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2])) #diferència dels dos primers valors de cada fila de la matriu\n",
    "                  \n",
    "    h_true = y_true[:,3] - y_true[:,1] #quarta columna d'una matriu - segona columna\n",
    "    w_true = y_true[:,2] - y_true[:,0] #tercera columna - primera\n",
    "\n",
    "    h_pred = yhat[:,3] - yhat[:,1] \n",
    "    w_pred = yhat[:,2] - yhat[:,0] \n",
    "    '''\n",
    "    delta_size = suma dels quadrats de les diferències entre les dimensions originals \n",
    "    i les dimensions reconstruïdes de l'imatge.\n",
    "    '''\n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72140c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss = tf.keras.losses.BinaryCrossentropy() #model que fa una classificació binaria \n",
    "regressloss = localization_loss #model que acabem de crear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b34a7fc1",
   "metadata": {},
   "source": [
    "### Test de les mètriques de 'loss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test, en les 2 cel·les inferiors s'hauria d'obtenir : <tf.Tensor: shape=(), dtype=float32, numpy=n>\n",
    "regressloss(y[1], coords) #y[0] ==> 0 o 1 (hi ha maduixa o no) , y[1] ==> coords (tot del batch sencer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb81dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss(y[0], classes) #numpy ==> probabilitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "localization_loss(y[1],coords)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "130bdab9",
   "metadata": {},
   "source": [
    "# 3. Entrenament de la intel·ligència artificial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "59fe1595",
   "metadata": {},
   "source": [
    "### 3.1 Creació del propi model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae1b2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector(Model): \n",
    "    def __init__(self, eyetracker,  **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.model = eyetracker\n",
    "\n",
    "    def compile(self, opt, classloss, localizationloss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.closs = classloss\n",
    "        self.lloss = localizationloss\n",
    "        self.opt = opt\n",
    "    '''\n",
    "    La funció train_step executa cada pas de l'entrenament del model. El model reb un lot de data \n",
    "    del entrenament (data que hem escollit per a 'train'),i calcula la pèrdua total (total_loss) que \n",
    "    consisteix en la suma de la pèrdua de localització (batch_localizationloss) i la meitat de la\n",
    "    pèrdua de classificació (batch_classloss). Finalment, calcula la perdua total i actualitza els\n",
    "    pesos del optimitzador.\n",
    "    '''\n",
    "    def train_step(self, batch, **kwargs): \n",
    "        \n",
    "        X, y = batch\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            classes, coords = self.model(X, training=True)\n",
    "            \n",
    "            batch_classloss = self.closs(y[0], classes)\n",
    "            batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "            \n",
    "            total_loss = batch_localizationloss+0.5*batch_classloss \n",
    "            \n",
    "            grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "            #el gradient representa la direcció i la magnitud en la qual s'ha\n",
    "            #d'ajustar cada paràmetre del model per reduir la pèrdua (loss) durant l'entrenament\n",
    "        \n",
    "        opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "    '''\n",
    "    Aquesta funció 'test_step' pilla la data de 'train' per avaluar-la i torna a calcular la pèrdua\n",
    "    total, la pèrdua de classificació i la pèrdua de localització. Això es fa per avaluar el \n",
    "    rendiment del model en dades noves.\n",
    "    '''\n",
    "    def test_step(self, batch, **kwargs): \n",
    "        X, y = batch\n",
    "        \n",
    "        classes, coords = self.model(X, training=False)\n",
    "        \n",
    "        batch_classloss = self.closs(y[0], classes)\n",
    "        batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "        total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "        \n",
    "    def call(self, X, **kwargs): \n",
    "        return self.model(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f405338",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Detector(detector)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a834cc1d",
   "metadata": {},
   "source": [
    "El 'mode.compile' configura el model per utilitzar l'optimitzador especificat per minimitzar la combinació de les funcions de pèrdua de classificació i regressió durant el procés d'entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1e7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt, classloss, regressloss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7e3b8c9f",
   "metadata": {},
   "source": [
    "### 3.2 Entrenament\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d11d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs' #Crea un directori on es guardarà la informació del Tensorboard "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0c141568",
   "metadata": {},
   "source": [
    "TensorBoard és una eina de visualització interactiva que s'utilitza en l'entrenament de models de xarxes neuronals per poder entendre millor el comportament del model durant l'entrenament i ajustar els paràmetres de manera més efectiva. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8616a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir) #crea un callback per registrar la informació del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2666bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = model.fit(train, epochs=10, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b5d0ac73",
   "metadata": {},
   "source": [
    "Aquesta última línia es passa tota la informació de train (osigui crida a tota la funció d'entrenament) per 10 iteracions (epochs) i registra les dades d'entrenament i validació durant l'entrenament a partir del callback de TensorBoard, llavors \"hist\" conté tota la info sobre les losses (pèrdues) i l'exactitud del model durant l'entrenament"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7f34d80",
   "metadata": {},
   "source": [
    "### 3.3 Anàlisi del rendiment de l'entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history #per veure totes les pèrdues (losses)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8bf7e81",
   "metadata": {},
   "source": [
    "El següent fragment mostra totes les losses de manera gràfica, en teoria tant les pèrdues i les pèrdues validades com les de classificació de localització i les totals haurien de ser valors molt semblants per a ser més exactes, en cas que no ho son deu haver-hi algun problema amb alguna anotation i no l'haurà processat bé (tampoc és un problema greu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb61c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, figsize=(20,5))\n",
    "\n",
    "ax[0].plot(hist.history['total_loss'], color='teal', label='loss')\n",
    "ax[0].plot(hist.history['val_total_loss'], color='orange', label='val loss')\n",
    "ax[0].title.set_text('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(hist.history['class_loss'], color='teal', label='class loss')\n",
    "ax[1].plot(hist.history['val_class_loss'], color='orange', label='val class loss')\n",
    "ax[1].title.set_text('Classification Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(hist.history['regress_loss'], color='teal', label='regress loss')\n",
    "ax[2].plot(hist.history['val_regress_loss'], color='orange', label='val regress loss')\n",
    "ax[2].title.set_text('Regression Loss')\n",
    "ax[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
