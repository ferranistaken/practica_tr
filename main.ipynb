{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7652d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install labelme tensorflow opencv-python matplotlib albumentations "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e0455a",
   "metadata": {},
   "source": [
    "# 1. Obtenció i tractament de dades"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9578d20b",
   "metadata": {},
   "source": [
    "### 1.1 Ús de la llibreria LabelMe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23d6376c",
   "metadata": {},
   "source": [
    "###  1.2 Creació de la base de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b42b8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importació de llibreries necessàries\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b7ac200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limitació de la memòria GPU \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce224428",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges = tf.data.Dataset.list_files('imatges\\\\*.jpg') # introduïm les imatges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f3a5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_imatge(imatge): #funció per a carregar imatges\n",
    "    byte_img = tf.io.read_file(imatge)\n",
    "    img = tf.image.decode_jpeg(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c7a78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges = imatges.map(carregar_imatge) #executem la funció "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0dad48be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[107, 111, 112],\n",
       "        [107, 111, 112],\n",
       "        [106, 110, 111],\n",
       "        ...,\n",
       "        [103, 108, 111],\n",
       "        [104, 109, 112],\n",
       "        [103, 108, 111]],\n",
       "\n",
       "       [[107, 111, 112],\n",
       "        [108, 112, 113],\n",
       "        [106, 110, 111],\n",
       "        ...,\n",
       "        [103, 108, 111],\n",
       "        [103, 108, 111],\n",
       "        [102, 107, 110]],\n",
       "\n",
       "       [[109, 110, 112],\n",
       "        [109, 110, 112],\n",
       "        [109, 110, 112],\n",
       "        ...,\n",
       "        [103, 108, 111],\n",
       "        [103, 108, 111],\n",
       "        [103, 108, 111]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[169, 168, 166],\n",
       "        [167, 166, 164],\n",
       "        [170, 166, 165],\n",
       "        ...,\n",
       "        [149, 148, 143],\n",
       "        [150, 149, 144],\n",
       "        [149, 148, 143]],\n",
       "\n",
       "       [[167, 165, 166],\n",
       "        [170, 168, 169],\n",
       "        [170, 166, 165],\n",
       "        ...,\n",
       "        [150, 149, 145],\n",
       "        [150, 149, 145],\n",
       "        [149, 148, 144]],\n",
       "\n",
       "       [[173, 171, 172],\n",
       "        [165, 163, 164],\n",
       "        [170, 166, 165],\n",
       "        ...,\n",
       "        [150, 149, 145],\n",
       "        [151, 150, 146],\n",
       "        [151, 150, 146]]], dtype=uint8)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imatges.as_numpy_iterator().next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa93ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imatgesDividir(dir_carpeta, n_imatges):\n",
    "    num_elements = len(os.listdir(os.path.join(dir_carpeta, \"imatges\")))\n",
    "    n_train = round(num_elements*0.7) # 70% de les imatges per entrenar\n",
    "    n_test = round(num_elements*0.15) # 15% de les imatges per provar\n",
    "    n_val = num_elements - (n_train + n_test) # 15% de les imatges per validar\n",
    "\n",
    "    llista = []\n",
    "    for i in range(1, (n_imatges + 1)):\n",
    "        llista.append(i)\n",
    "\n",
    "    while len(llista) > n_train:\n",
    "        if (len(os.listdir(os.path.join(dir_carpeta,\"dades\",\"test\")))-1)< n_test:\n",
    "            for i in range(n_test):\n",
    "                n = random.choice(llista)\n",
    "                nom = str(str(n) + \".jpg\")\n",
    "                shutil.move(os.path.join(dir_carpeta, \"imatges\", nom ), os.path.join(dir_carpeta, \"dades\", \"test\" , \"imatges\"))\n",
    "                llista.remove(n)\n",
    "\n",
    "        if (len(os.listdir(os.path.join(dir_carpeta,\"dades\",\"val\")))-1) < n_val:\n",
    "            for i in range(n_val):\n",
    "                n = random.choice(llista)\n",
    "                nom = str(str(n) + \".jpg\")\n",
    "                shutil.move(os.path.join(dir_carpeta, \"imatges\", nom), os.path.join(dir_carpeta,\"dades\" , \"val\", \"imatges\"))\n",
    "                llista.remove(n)\n",
    "\n",
    "    for i in llista:\n",
    "        nom = str(i) + \".jpg\"\n",
    "        shutil.move(os.path.join(dir_carpeta, \"imatges\", nom), os.path.join(dir_carpeta, \"dades\",\"train\", \"imatges\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8643289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear la carpeta principal\n",
    "os.mkdir(\"dades\")\n",
    "\n",
    "# Crear les subcarpetes dins de la carpeta principal\n",
    "for subcarpeta in [\"train\", \"test\", \"val\"]:\n",
    "    path_subcarpeta = os.path.join(\"dades\", subcarpeta)\n",
    "    os.mkdir(path_subcarpeta)\n",
    "    path_subsubcarpeta = os.path.join(\"dades\", subcarpeta, \"imatges\")\n",
    "    os.mkdir(path_subsubcarpeta)\n",
    "    path_subsubcarpeta2 = os.path.join(\"dades\", subcarpeta, \"labels\")\n",
    "    os.mkdir(path_subsubcarpeta2)\n",
    "\n",
    "imatgesDividir('\\practica_tr',300) #divisió de les carpetes i de les imatges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b439be43",
   "metadata": {},
   "source": [
    "### Partició de les dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7dce6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mou les els labels a les seves respectives carpetes\n",
    "def moureLabels(dir_carpeta):\n",
    "    for carpeta in ['train','test','val']:\n",
    "        for arxiu in os.listdir(os.path.join(dir_carpeta,'dades', carpeta, 'imatges')): #per cada arxiu en cada carpeta\n",
    "            n = arxiu.split(\".\")\n",
    "            json = str(n[0] + \".json\")\n",
    "            shutil.move(os.path.join(dir_carpeta, \"labels\", json ), os.path.join(dir_carpeta, \"dades\", carpeta, \"labels\"))#canviem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2277dd51",
   "metadata": {},
   "outputs": [],
   "source": [
    "moureLabels('\\practica_tr')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70389c",
   "metadata": {},
   "source": [
    "### 1.2.1 Ús de la llibreria Albumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "071c1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "93969970",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=1024, height=1024),\n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.5),\n",
    "                         alb.RandomGamma(p=0.7), \n",
    "                         alb.RGBShift(p=0.5), \n",
    "                         alb.VerticalFlip(p=0.7)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', \n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "7e41c01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"aug_dades\")\n",
    "\n",
    "# Crear les subcarpetes dins de la carpeta principal\n",
    "for subcarpeta in [\"train\", \"test\", \"val\"]:\n",
    "    path_subcarpeta = os.path.join(\"aug_dades\", subcarpeta)\n",
    "    os.mkdir(path_subcarpeta)\n",
    "    path_subsubcarpeta = os.path.join(\"aug_dades\", subcarpeta, \"imatges\")\n",
    "    os.mkdir(path_subsubcarpeta)\n",
    "    path_subsubcarpeta2 = os.path.join(\"aug_dades\", subcarpeta, \"labels\")\n",
    "    os.mkdir(path_subsubcarpeta2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "6a36e346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requested crop size (1024, 1024) is larger than the image size (512, 512)\n",
      "Requested crop size (1024, 1024) is larger than the image size (512, 512)\n",
      "Requested crop size (1024, 1024) is larger than the image size (512, 512)\n",
      "Requested crop size (1024, 1024) is larger than the image size (512, 512)\n"
     ]
    }
   ],
   "source": [
    "classes_fruita = {\"poma\": [1,0,0], \"pera\": [0,1,0] , \"mandarina\": [0,0,1]}\n",
    "partitions = ['train', 'test', 'val']\n",
    "\n",
    "for partition in partitions:\n",
    "    input_folder = os.path.join('dades', partition, 'imatges')\n",
    "    output_folder = os.path.join('aug_dades', partition, 'imatges')\n",
    "\n",
    "    for imatge in os.listdir(input_folder):\n",
    "        img_path = os.path.join(input_folder, imatge)\n",
    "        img = cv2.imread(img_path)\n",
    "        label_path = os.path.join('dades', partition, 'labels', f'{imatge.split(\".\")[0]}.json')\n",
    "\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            for shape in label['shapes']:\n",
    "                class_name = shape['label'] \n",
    "                class_id = classes_fruita[class_name]\n",
    "                coords = shape['points']\n",
    "                coords = [(coords[0][0]/1024), (coords[0][1]/1024), (coords[1][0]/1024), (coords[1][1]/1024)]\n",
    "\n",
    "                try:\n",
    "                    for x in range(5):\n",
    "                        augmented = augmentor(image=img, bboxes=[coords], class_labels=[class_name])\n",
    "                        augmented_img = augmented['image']\n",
    "\n",
    "                        annotation = {\n",
    "                            'image': f'{imatge.split(\".\")[0]}.{x}.jpg',\n",
    "                            'bbox': augmented['bboxes'],\n",
    "                            'class': class_id,\n",
    "                        }\n",
    "                        output_img_path = os.path.join(output_folder, annotation['image'])\n",
    "                        cv2.imwrite(output_img_path, augmented_img)\n",
    "\n",
    "                        output_json_path = os.path.join('aug_dades', partition, 'labels', f'{imatge.split(\".\")[0]}.{x}.json')\n",
    "                        with open(output_json_path, 'w') as f:\n",
    "                            json.dump(annotation, f) \n",
    "                except Exception as e:\n",
    "                    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0c55a",
   "metadata": {},
   "source": [
    "### Incloure imatges creades amb Albumentations a la Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "7f16bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imatges = tf.data.Dataset.list_files('aug_dades\\\\train\\\\imatges\\\\*.jpg',shuffle=False)\n",
    "train_imatges = train_imatges.map(carregar_imatge)\n",
    "train_imatges = train_imatges.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "train_imatges = train_imatges.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "05456564",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imatges = tf.data.Dataset.list_files('aug_dades\\\\test\\\\imatges\\\\*.jpg', shuffle=False)\n",
    "test_imatges = test_imatges.map(carregar_imatge)\n",
    "test_imatges = test_imatges.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "test_imatges = test_imatges.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "167107c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imatges = tf.data.Dataset.list_files('aug_dades\\\\val\\\\imatges\\\\*.jpg', shuffle=False)\n",
    "val_imatges = val_imatges.map(carregar_imatge)\n",
    "val_imatges = val_imatges.map(lambda x: tf.image.resize(x, (120,120)))\n",
    "val_imatges = val_imatges.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "59755dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.75385624, 0.7556863 , 0.74692816],\n",
       "        [0.7550458 , 0.7598824 , 0.74027455],\n",
       "        [0.74509805, 0.7529412 , 0.7411765 ],\n",
       "        ...,\n",
       "        [0.7019608 , 0.7019608 , 0.6959477 ],\n",
       "        [0.6989543 , 0.70287585, 0.683268  ],\n",
       "        [0.6998693 , 0.7058824 , 0.69545984]],\n",
       "\n",
       "       [[0.7490196 , 0.7490196 , 0.7411765 ],\n",
       "        [0.75094116, 0.75094116, 0.743098  ],\n",
       "        [0.7490196 , 0.7490196 , 0.7411765 ],\n",
       "        ...,\n",
       "        [0.69411767, 0.7019608 , 0.68235296],\n",
       "        [0.6929412 , 0.7007843 , 0.6890196 ],\n",
       "        [0.69803923, 0.69803923, 0.6901961 ]],\n",
       "\n",
       "       [[0.7488671 , 0.7488671 , 0.74102396],\n",
       "        [0.7517647 , 0.7517647 , 0.7517647 ],\n",
       "        [0.74956423, 0.74956423, 0.74956423],\n",
       "        ...,\n",
       "        [0.7013069 , 0.7013069 , 0.69346374],\n",
       "        [0.6901961 , 0.69803923, 0.69411767],\n",
       "        [0.69411767, 0.7019608 , 0.6901961 ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.7527886 , 0.74886703, 0.7350108 ],\n",
       "        [0.7490196 , 0.7411765 , 0.74509805],\n",
       "        [0.74444443, 0.74444443, 0.74444443],\n",
       "        ...,\n",
       "        [0.6581696 , 0.6620912 , 0.6385618 ],\n",
       "        [0.6611112 , 0.6571896 , 0.6493465 ],\n",
       "        [0.65474933, 0.65082777, 0.6351415 ]],\n",
       "\n",
       "       [[0.74691486, 0.7429933 , 0.73515016],\n",
       "        [0.74235266, 0.74235266, 0.74235266],\n",
       "        [0.7490196 , 0.74509805, 0.7372549 ],\n",
       "        ...,\n",
       "        [0.65882355, 0.654902  , 0.63529414],\n",
       "        [0.66156894, 0.6576474 , 0.64980423],\n",
       "        [0.6579219 , 0.65400034, 0.63831407]],\n",
       "\n",
       "       [[0.74810433, 0.74418277, 0.7363396 ],\n",
       "        [0.7520259 , 0.74418277, 0.74810433],\n",
       "        [0.7529412 , 0.7490196 , 0.7411765 ],\n",
       "        ...,\n",
       "        [0.65882355, 0.654902  , 0.64705884],\n",
       "        [0.654902  , 0.654902  , 0.6488894 ],\n",
       "        [0.654902  , 0.654902  , 0.64705884]]], dtype=float32)"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_imatges.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0900d8c7",
   "metadata": {},
   "source": [
    "### 2.5 Carregar labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "8f31855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_labels(label_path):\n",
    "    with open(label_path.numpy(), 'r', encoding = \"utf-8\") as f:\n",
    "        label = json.load(f)\n",
    "        \n",
    "    return [label['class']], label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "f279ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_dades\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "2fbc102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('aug_dades\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "a532244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('aug_dades\\\\val\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "f65cbee7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0]], dtype=uint8),\n",
       " array([[0.3005, 0.2437, 0.7026, 0.6504]], dtype=float16))"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9566b",
   "metadata": {},
   "source": [
    "### Combinar etiquetes i imatges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "00975b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elements={}\n",
    "for carpeta in ['train','test','val']:\n",
    "    x = len(os.listdir(os.path.join('aug_dades', carpeta, 'imatges')))\n",
    "    num_elements.update({carpeta : round(x * 1.5)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "2ea1c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_imatges, train_labels))\n",
    "train = train.shuffle(num_elements['train'])\n",
    "train = train.batch(8)\n",
    "train = train.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "c0ba0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_imatges, test_labels))\n",
    "test = test.shuffle(num_elements['test'])\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "910bd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((val_imatges, val_labels))\n",
    "val = val.shuffle(num_elements['val'])\n",
    "val = val.batch(8)\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "938f7528",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 120, 120, 3)"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.as_numpy_iterator().next()[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64bdd4d3",
   "metadata": {},
   "source": [
    "# 2. Preparació de la intel·ligència artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "254f476e",
   "metadata": {},
   "source": [
    "### 2.1 Descarregar i carregar el model VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "d709c624",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras.models\n",
    "import tensorflow.keras.layers\n",
    "import tensorflow.keras.applications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "a87f38e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "cd1cd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False) \n",
    "#Marca que les ultimes capes de la xarxa no les utilitzarem perquè afegirem les nostres pròpies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "26209fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''\n",
    "La funció crea i retorna un model de xarxa neuronal convolucional per a la detecció dels objectes. \n",
    "El model té dues parts: una per a determinar si una imatge conté algun objecte i una altra per a localitzar l'obkecte (poma, pera o mandarina) a l'imatge. \n",
    "Al utilitzar VGG16, com que esta pre-entrenada, les característiques del input\n",
    "i les classifica en dues branques que son les dues parts mencionades abans de manera automàtica. \n",
    "'''\n",
    "def build_model(): \n",
    "    input_layer = Input(shape=(120,120,3))\n",
    "    \n",
    "    vgg = VGG16(include_top=False)(input_layer)\n",
    "    #Model de classificació\n",
    "    f1 = GlobalMaxPooling2D()(vgg)\n",
    "    class1 = Dense(2048, activation='relu')(f1) #relu == funció que determina la classe; \n",
    "    class2 = Dense(3, activation='softmax')(class1) # sigmoid == funció que determina la presició de la classe\n",
    "\n",
    "    # sigmoid = f(x) = 1/(1+e^-x)\n",
    "    \n",
    "    #Model de localització de coordenades\n",
    "    f2 = GlobalMaxPooling2D()(vgg)\n",
    "    regress1 = Dense(2048, activation='relu')(f2)\n",
    "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
    "    \n",
    "    detector = Model(inputs=input_layer, outputs=[class2, regress2])\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "d47d7819",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "b1f7e89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "1a70487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 120, 120, 3)"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "12e85f12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    }
   ],
   "source": [
    "classes, coords = detector.predict(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3022fa19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.29551685, 0.3659763 , 0.33850685],\n",
       "       [0.3078581 , 0.34526628, 0.3468756 ],\n",
       "       [0.4756917 , 0.30089733, 0.22341104],\n",
       "       [0.38100597, 0.3189793 , 0.3000147 ],\n",
       "       [0.5267785 , 0.28630996, 0.1869114 ],\n",
       "       [0.4155774 , 0.3133717 , 0.27105093],\n",
       "       [0.5241034 , 0.17973018, 0.2961664 ],\n",
       "       [0.46964967, 0.24831405, 0.28203636]], dtype=float32)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes , coords\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e82e086",
   "metadata": {},
   "source": [
    "### 2.2 Funcions de pèrdua i optimitzadors\n",
    "Els optimitzadors són algorismes que s’utilitzen per ajustar els pesos d’una xarxa neuronal durant l’entrenament. Els optimitzadors són responsables de minimitzar la funció de pèrdua de la xarxa neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "4a95066a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nEn el context de les xarxes neuronals, un optimitzador és un algorisme\\nque ajuda a ajustar els paràmetres de la xarxa per aconseguir una millor precisió.\\nL'optimitzador Adam és un exemple d'això i ajuda a l'optimitzador a convergir més ràpidament\\ni amb més precisió.\\n\""
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001) #li introduïm el decay que hem calculat a l'optimitzador\n",
    "\n",
    "'''\n",
    "En el context de les xarxes neuronals, un optimitzador és un algorisme\n",
    "que ajuda a ajustar els paràmetres de la xarxa per aconseguir una millor precisió.\n",
    "L'optimitzador Adam és un exemple d'això i ajuda a l'optimitzador a convergir més ràpidament\n",
    "i amb més precisió.\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bb0627",
   "metadata": {},
   "source": [
    "### Creació de 'Localitzation Loss' i 'Classification Loss'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400ff5f5",
   "metadata": {},
   "source": [
    "La funció té dos components: la pèrdua de localització i la pèrdua de classificació.\n",
    "La pèrdua de localització mesura la diferència entre les coordenades dels quadres delimitadors \n",
    "predits i les coordenades dels quadres delimitadors reals. La pèrdua de classificació mesura la\n",
    "diferència entre les probabilitats de classe predites i les probabilitats de classe reals. \n",
    "En aquesta funció, només es calcula la pèrdua de localització.\n",
    "\n",
    "La funció té com a entrada dos tensors: y_true i yhat. \n",
    "y_true conté les coordenades dels quadres delimitadors reals i\n",
    "les probabilitats de classe reals per a cada objecte en la imatge d’entrada.\n",
    "yhat conté les coordenades dels quadres delimitadors predits i les\n",
    "probabilitats de classe predites per a cada objecte en la imatge d’entrada.\n",
    "\n",
    "La funció calcula la pèrdua de localització sumant el quadrat de la diferència\n",
    "entre les coordenades dels quadres delimitadors reals i les coordenades dels quadres\n",
    "delimitadors predits. A continuació, calcula la diferència entre l’amplada i l’alçada\n",
    "dels quadres delimitadors reals i els quadres delimitadors predits i suma els quadrats\n",
    "d’aquestes diferències. Finalment, retorna la suma de les dues pèrdues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "a0159efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, yhat):#primer valor: coordenades reals, segon valor: coordenades previstes     \n",
    "    y_true = tf.reshape(y_true, (8, 4))\n",
    "    \n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2])) #diferència dels dos primers valors de cada fila de la matriu\n",
    "                  \n",
    "    h_true = y_true[:,3] - y_true[:,1] #quarta columna d'una matriu - segona columna\n",
    "    w_true = y_true[:,2] - y_true[:,0] #tercera columna - primera\n",
    "\n",
    "    h_pred = yhat[:,3] - yhat[:,1] \n",
    "    w_pred = yhat[:,2] - yhat[:,0] \n",
    "    '''\n",
    "    delta_size = suma dels quadrats de les diferències entre les dimensions originals \n",
    "    i les dimensions reconstruïdes de l'imatge.\n",
    "    '''\n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "72140c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss = tf.keras.losses.CategoricalCrossentropy() #model que fa una classificació binaria \n",
    "regressloss = localization_loss #model que acabem de crear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "4ada2dbe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float16, numpy=5.773>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regressloss(y[1], coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "40377733",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=1.1806874>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_reshaped = tf.reshape(y[0], (8, 3))\n",
    "classloss(y_reshaped, classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "cf6a98f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float16, numpy=5.773>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "localization_loss(y[1], coords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "130bdab9",
   "metadata": {},
   "source": [
    "# 3. Entrenament de la intel·ligència artificial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59fe1595",
   "metadata": {},
   "source": [
    "### 3.1 Creació del propi model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "ae1b2c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Detector(Model): \n",
    "    def __init__(self, fruita,  **kwargs): \n",
    "        super().__init__(**kwargs)\n",
    "        self.model = fruita\n",
    "\n",
    "    def compile(self, opt, classloss, localizationloss, **kwargs):\n",
    "        super().compile(**kwargs)\n",
    "        self.closs = classloss\n",
    "        self.lloss = localizationloss\n",
    "        self.opt = opt\n",
    "    '''\n",
    "    La funció train_step executa cada pas de l'entrenament del model. El model rep un lot de dades\n",
    "    del entrenament (data que hem escollit per a 'train'),i calcula la pèrdua total (total_loss) que \n",
    "    consisteix en la suma de la pèrdua de localització (batch_localizationloss) i la meitat de la\n",
    "    pèrdua de classificació (batch_classloss). Finalment, calcula la perdua total i actualitza els\n",
    "    pesos.\n",
    "    '''\n",
    "    def train_step(self, batch, **kwargs): \n",
    "        \n",
    "        X, y = batch\n",
    "        \n",
    "        with tf.GradientTape() as tape: \n",
    "            classes, coords = self.model(X, training=True)\n",
    "            \n",
    "            batch_classloss = self.closs(tf.reshape(y[0], (8, 3)), classes)\n",
    "            batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "            \n",
    "            total_loss = batch_localizationloss+0.5*batch_classloss \n",
    "            \n",
    "            grad = tape.gradient(total_loss, self.model.trainable_variables)\n",
    "            #el gradient representa la direcció i la magnitud en la qual s'ha\n",
    "            #d'ajustar cada paràmetre del model per reduir la pèrdua (loss) durant l'entrenament\n",
    "        \n",
    "        opt.apply_gradients(zip(grad, self.model.trainable_variables))\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "    '''\n",
    "    Aquesta funció 'test_step' agafa la data de 'train' per avaluar-la i torna a calcular la pèrdua\n",
    "    total, la pèrdua de classificació i la pèrdua de localització. Això es fa per avaluar el \n",
    "    rendiment del model en dades noves.\n",
    "    '''\n",
    "    def test_step(self, batch, **kwargs): \n",
    "        X, y = batch\n",
    "        \n",
    "        classes, coords = self.model(X, training=False)\n",
    "        \n",
    "        batch_classloss = self.closs(y[0], classes)\n",
    "        batch_localizationloss = self.lloss(tf.cast(y[1], tf.float32), coords)\n",
    "        total_loss = batch_localizationloss+0.5*batch_classloss\n",
    "        \n",
    "        return {\"total_loss\":total_loss, \"class_loss\":batch_classloss, \"regress_loss\":batch_localizationloss}\n",
    "        \n",
    "    def call(self, X, **kwargs): \n",
    "        return self.model(X, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "2f405338",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Detector(detector)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a834cc1d",
   "metadata": {},
   "source": [
    "El 'mode.compile' configura el model per utilitzar l'optimitzador especificat per minimitzar la combinació de les funcions de pèrdua de classificació i regressió durant el procés d'entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "5d1e7058",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(opt, classloss, regressloss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e3b8c9f",
   "metadata": {},
   "source": [
    "### 3.2 Entrenament\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "6d11d3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir='logs' #Crea un directori on es guardarà la informació del Tensorboard "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c141568",
   "metadata": {},
   "source": [
    "TensorBoard és una eina de visualització interactiva que s'utilitza en l'entrenament de models de xarxes neuronals per poder entendre millor el comportament del model durant l'entrenament i ajustar els paràmetres de manera més efectiva. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "8616a537",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir) #crea un callback per registrar la informació del model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "e2666bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/130 [============================>.] - ETA: 3s - total_loss: 0.0461 - class_loss: 0.0150 - regress_loss: 0.0386"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\nDetected at node 'Reshape' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"t:\\env\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"t:\\env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"t:\\env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\odena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Users\\odena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Users\\odena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\odena\\AppData\\Local\\Temp\\ipykernel_10856\\2935669400.py\", line 1, in <module>\n      hist = model.fit(train, epochs=1, validation_data=val, callbacks=[tensorboard_callback])\n    File \"t:\\env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"t:\\env\\Lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"t:\\env\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"t:\\env\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"t:\\env\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\odena\\AppData\\Local\\Temp\\ipykernel_10856\\579508060.py\", line 25, in train_step\n      batch_classloss = self.closs(tf.reshape(y[0], (8, 3)), classes)\nNode: 'Reshape'\nInput to reshape is a tensor with 9 values, but the requested shape has 24\n\t [[{{node Reshape}}]] [Op:__inference_train_function_85217]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mt:\\practica_tr\\main.ipynb Cell 69\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/t%3A/practica_tr/main.ipynb#Y125sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m hist \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train, epochs\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49mval, callbacks\u001b[39m=\u001b[39;49m[tensorboard_callback])\n",
      "File \u001b[1;32mt:\\env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mt:\\env\\Lib\\site-packages\\tensorflow\\python\\eager\\execute.py:52\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 52\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39mTFE_Py_Execute(ctx\u001b[39m.\u001b[39m_handle, device_name, op_name,\n\u001b[0;32m     53\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[0;32m     54\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     55\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\nDetected at node 'Reshape' defined at (most recent call last):\n    File \"<frozen runpy>\", line 198, in _run_module_as_main\n    File \"<frozen runpy>\", line 88, in _run_code\n    File \"t:\\env\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n      app.launch_new_instance()\n    File \"t:\\env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1043, in launch_instance\n      app.start()\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 725, in start\n      self.io_loop.start()\n    File \"t:\\env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n      self.asyncio_loop.run_forever()\n    File \"C:\\Users\\odena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n      self._run_once()\n    File \"C:\\Users\\odena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n      handle._run()\n    File \"C:\\Users\\odena\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\asyncio\\events.py\", line 80, in _run\n      self._context.run(self._callback, *self._args)\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in dispatch_queue\n      await self.process_one()\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 502, in process_one\n      await dispatch(*args)\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 409, in dispatch_shell\n      await result\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 729, in execute_request\n      reply_content = await reply_content\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n      res = shell.run_cell(\n    File \"t:\\env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 540, in run_cell\n      return super().run_cell(*args, **kwargs)\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3009, in run_cell\n      result = self._run_cell(\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3064, in _run_cell\n      result = runner(coro)\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n      coro.send(None)\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3269, in run_cell_async\n      has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3448, in run_ast_nodes\n      if await self.run_code(code, result, async_=asy):\n    File \"t:\\env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3508, in run_code\n      exec(code_obj, self.user_global_ns, self.user_ns)\n    File \"C:\\Users\\odena\\AppData\\Local\\Temp\\ipykernel_10856\\2935669400.py\", line 1, in <module>\n      hist = model.fit(train, epochs=1, validation_data=val, callbacks=[tensorboard_callback])\n    File \"t:\\env\\Lib\\site-packages\\keras\\utils\\traceback_utils.py\", line 65, in error_handler\n      return fn(*args, **kwargs)\n    File \"t:\\env\\Lib\\site-packages\\keras\\engine\\training.py\", line 1685, in fit\n      tmp_logs = self.train_function(iterator)\n    File \"t:\\env\\Lib\\site-packages\\keras\\engine\\training.py\", line 1284, in train_function\n      return step_function(self, iterator)\n    File \"t:\\env\\Lib\\site-packages\\keras\\engine\\training.py\", line 1268, in step_function\n      outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"t:\\env\\Lib\\site-packages\\keras\\engine\\training.py\", line 1249, in run_step\n      outputs = model.train_step(data)\n    File \"C:\\Users\\odena\\AppData\\Local\\Temp\\ipykernel_10856\\579508060.py\", line 25, in train_step\n      batch_classloss = self.closs(tf.reshape(y[0], (8, 3)), classes)\nNode: 'Reshape'\nInput to reshape is a tensor with 9 values, but the requested shape has 24\n\t [[{{node Reshape}}]] [Op:__inference_train_function_85217]"
     ]
    }
   ],
   "source": [
    "hist = model.fit(train, epochs=1, validation_data=val, callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d0ac73",
   "metadata": {},
   "source": [
    "Aquesta última línia es passa tota la informació de train (osigui crida a tota la funció d'entrenament) per 10 iteracions (epochs) i registra les dades d'entrenament i validació durant l'entrenament a partir del callback de TensorBoard, llavors \"hist\" conté tota la info sobre les losses (pèrdues) i l'exactitud del model durant l'entrenament"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7f34d80",
   "metadata": {},
   "source": [
    "### 3.3 Anàlisi del rendiment de l'entrenament"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20d354a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hist.history #per veure totes les pèrdues (losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bf7e81",
   "metadata": {},
   "source": [
    "El següent fragment mostra totes les losses de manera gràfica, en teoria tant les pèrdues i les pèrdues validades com les de classificació de localització i les totals haurien de ser valors molt semblants per a ser més exactes, en cas que no ho son deu haver-hi algun problema amb alguna anotation i no l'haurà processat bé (tampoc és un problema greu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fb61c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=3, figsize=(20,5))\n",
    "\n",
    "ax[0].plot(hist.history['total_loss'], color='teal', label='loss')\n",
    "ax[0].plot(hist.history['val_total_loss'], color='orange', label='val loss')\n",
    "ax[0].title.set_text('Loss')\n",
    "ax[0].legend()\n",
    "\n",
    "ax[1].plot(hist.history['class_loss'], color='teal', label='class loss')\n",
    "ax[1].plot(hist.history['val_class_loss'], color='orange', label='val class loss')\n",
    "ax[1].title.set_text('Classification Loss')\n",
    "ax[1].legend()\n",
    "\n",
    "ax[2].plot(hist.history['regress_loss'], color='teal', label='regress loss')\n",
    "ax[2].plot(hist.history['val_regress_loss'], color='orange', label='val regress loss')\n",
    "ax[2].title.set_text('Regression Loss')\n",
    "ax[2].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5669ad25",
   "metadata": {},
   "source": [
    "### Provem i desem el model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4561a424",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96958bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "Detector.save(\"detector_fruites.h5\") #el desem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c4c925",
   "metadata": {},
   "source": [
    "### El provem amb la webcam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d2d1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Detector = load_model('detector_fruites.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7accfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "while cap.isOpened():\n",
    "    _ , frame = cap.read()\n",
    "    frame = frame[50:500, 50:500,:]\n",
    "    \n",
    "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    resized = tf.image.resize(rgb, (120,120))\n",
    "    \n",
    "    yhat = Detector.predict(np.expand_dims(resized/255,0))\n",
    "    sample_coords = yhat[1][0]\n",
    "    \n",
    "    if yhat[0] > 0.5: \n",
    "        # Controls the main rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.multiply(sample_coords[:2], [450,450]).astype(int)),\n",
    "                      tuple(np.multiply(sample_coords[2:], [450,450]).astype(int)), \n",
    "                            (255,0,0), 2)\n",
    "        # Controls the label rectangle\n",
    "        cv2.rectangle(frame, \n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int), \n",
    "                                    [0,-30])),\n",
    "                      tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                    [80,0])), \n",
    "                            (255,0,0), -1)\n",
    "        \n",
    "        if yhat[0] > 0.8 and yhat[0] < 1.2:\n",
    "        # Controls the text rendered\n",
    "            cv2.putText(frame, 'poma', tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                                [0,-5])),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        elif yhat[0] > 1.8 and yhat[0] < 2.2:\n",
    "            cv2.putText(frame, 'pera', tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                                [0,-5])),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        elif yhat[0] > 2.8 and yhat[0] < 3.2:\n",
    "                        cv2.putText(frame, 'mandarina', tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                                [0,-5])),\n",
    "                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        else:           \n",
    "                cv2.putText(frame, 'no ho tinc clar', tuple(np.add(np.multiply(sample_coords[:2], [450,450]).astype(int),\n",
    "                                                [0,-5])),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "        \n",
    "    cv2.imshow('EyeTrack', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
