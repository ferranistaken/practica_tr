{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33e0455a",
   "metadata": {},
   "source": [
    "# 1. Recol·lecció i tractament de dades"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa979ccf",
   "metadata": {},
   "source": [
    " * 1.1 Executem la llibreria LabelMe, que manualment ens permetrà obtenir unes coordenades que marquin la àrea del objecte que volem detectar. Aquesta llibreria ens retornarà un arxiu .json amb els valors numèrics dels punts marcats. Amb aquests valors, la xarxa neuronal serà capaç d'entrenar-se. Haurem de crear una carpeta que anomenarem \"labels\" on hi aniran aquestes \"etiquetes\" en format .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme #execució de la llibreria labelme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23d6376c",
   "metadata": {},
   "source": [
    "# 2. Creació de la base de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42b8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importació de llibreries necessàries\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ac200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limitació de la memòria GPU \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce224428",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges = tf.data.Dataset.list_files('data\\\\images\\\\*.png') # introduïm les imatges a la base de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_imatge(imatge): #funció per a carregar imatges\n",
    "    byte_img = tf.io.read_file(imatge)\n",
    "    img = tf.io.decode_png(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges = imatges.map(carregar_imatge) # executem la funció per carregar les imatges en la base de dades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges.as_numpy_iterator().next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantImatgesDividir(dir_carpeta):\n",
    "    num_elements = len(os.listdir(dir_carpeta))\n",
    "    n_entrenar = round(num_elements*0.7) # 70% de les imatges per entrenar\n",
    "    n_provar = round(num_elements*0.15) # 15% de les imatges per provar\n",
    "    n_validar = num_elements - (n_entrenar + n_provar) # 15% de les imatges per validar\n",
    "    print(f\"{n_entrenar} --> 'train' \\n {n_provar} --> 'test' \\n {n_validar} --> 'val'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantImatgesDividir('T:\\REP\\deteccio_prova\\data\\images') # s'han de dividir manualment les imatges (intentant que sigui aleatori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dce6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mou les els labels a les seves respectives carpetes\n",
    "for carpeta in ['train','test','val']:\n",
    "    for arxiu in os.listdir(os.path.join('data', carpeta, 'images')): #per cada arxiu en cada carpeta\n",
    "        nom_arxiu = arxiu.split('.')[0]+'.json' #extreu el nom de l'arxiu\n",
    "        dir_existent = os.path.join('data','labels', nom_arxiu)#crea possible direcció\n",
    "        if os.path.exists(dir_existent): #si la possible direcció existeix, desplaça l'arxiu .json corresponent\n",
    "            nova_dir = os.path.join('data',carpeta,'labels',nom_arxiu)\n",
    "            os.replace(dir_existent, nova_dir)#canviem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70389c",
   "metadata": {},
   "source": [
    "### 2.1 Augmentem la quantitat de dades amb la llibreria Albumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071c1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93969970",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=1024, height=1024),\n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', #format de coords que volem (buscar docs)\n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train','test','val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [1024,1024,1024,1024]))\n",
    "            # ^^^ carregar imatges i json ^^^\n",
    "\n",
    "        try: \n",
    "            for x in range(60):# quantitat d'imatges que surten d'una imatge base\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['Maduixa'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'),augmented['image'])\n",
    "                \n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "                    '''\n",
    "                     La variable “annotation” és un diccionari que conté informació sobre la imatge i \n",
    "                     la seva anotació. Si el fitxer d’anotació existeix, el codi afegeix la caixa delimitadora\n",
    "                     i la classe corresponent a l’objecte detectat a l’estructura “annotation”. \n",
    "                     Si el fitxer d’anotació no existeix, el codi assigna una caixa delimitadora i \n",
    "                     una classe buida a l’estructura “annotation”.\n",
    "                    '''\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0c55a",
   "metadata": {},
   "source": [
    "### 2.2 Incloure imatges creades amb Albumentations a la Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obrim les carpetes amb les img a manipular i les carreguem\n",
    "train_images = tf.data.Dataset.list_files('aug_data\\\\train\\\\images\\\\*.jpg',shuffle=False)\n",
    "train_images = train_images.map(carregar_imatge)\n",
    "#Es fa resize de les img i també baixem l'escala de la imatge a 1\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "train_images = train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05456564",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files('aug_data\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
    "test_images = test_images.map(carregar_imatge)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "test_images = test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167107c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = tf.data.Dataset.list_files('aug_data\\\\val\\\\images\\\\*.jpg', shuffle=False)\n",
    "val_images = val_images.map(carregar_imatge)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "val_images = val_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0900d8c7",
   "metadata": {},
   "source": [
    "### 2.3 Carregar Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funció que carrega els labels\n",
    "def carregar_labels(x):\n",
    "    with open(x.numpy(), 'r', encoding='utf-8') as f:\n",
    "        label = json.load(f)\n",
    "    return [label['class']],label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f279ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_data\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))#tf_py_function(funció, paràmetres, tipus de retorn) \n",
    "#obre els labels i els aplica la funció carregar_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('aug_data\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('aug_data\\\\val\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9566b",
   "metadata": {},
   "source": [
    "### 2.4 Combinar labels i imatges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00975b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cal comprovar quantes imatges hi ha en cada carpeta\n",
    "print(\"Train: \" + str(len(train_labels)) + \", Test: \" + str(len(test_labels)) + \", Val: \" + str(len(val_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images, train_labels)) #mètode que junta les imatges amb els labels\n",
    "train = train.shuffle(2000) #posar el número que hi ha apoximat cap amunt, en aquest cas 2000\n",
    "train = train.batch(8)#crear lots de 8\n",
    "train = train.prefetch(4)#redueix la capacitat de procesar per evitar errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "test = test.shuffle(500)\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((val_images, val_labels))\n",
    "val = val.shuffle(500)\n",
    "val = val.batch(8)\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18989ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.as_numpy_iterator().next()[1]\n",
    "'''\n",
    "Amb això visualitzem la manera en què hem codificat i guardat les imatges;\n",
    "Obtindrem això:\n",
    "(array([[n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n]], dtype=uint8),\n",
    " array([[n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n]], dtype=float16))\n",
    "\n",
    "la primera columna ens indica la classe de la imatge, és a dir, l'objecte que hi ha a la imatge\n",
    "la segona columna ens indica la bounding box de la imatge, és a dir, la posició de l'objecte a la imatge\n",
    "\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "64bdd4d3",
   "metadata": {},
   "source": [
    "# 3. Creació de la IA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1288df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#La línia 2 importa les capes de Input, de convolució 2D, de connexió i de agregació màxima global\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, GlobalMaxPooling2D\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1cd114",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(include_top=False) \n",
    "#Marca que les ultimes capes de la xarxa no les utilitzarem perque afegirem les nostrtes propies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ff4fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26209fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "La funció crea i retorna un model de xarxa neuronal convolucional per a la detecció dels objectes. \n",
    "El model té dues parts: una per a determinar si una imatge té una maduixa o no i una altra per a localitzar la maduixa en la imatge. \n",
    "Al utilitzar VGG16, com que esta pre-entrenada, les característiques del INPUT\n",
    "i les classifica en dues branques que son les dues parts mencionades abans de manera \"automàtica\". \n",
    "'''\n",
    "\n",
    "def build_model(): \n",
    "    input_layer = Input(shape=(250,250,3))\n",
    "    \n",
    "    vgg = VGG16(include_top=False)(input_layer)\n",
    "    #Model de classificació\n",
    "    f1 = GlobalMaxPooling2D()(vgg)\n",
    "    class1 = Dense(2048, activation='relu')(f1) #relu == funció que determina la classe; si és maduixa o no\n",
    "    class2 = Dense(1, activation='sigmoid')(class1) # sigmoid == funció que determina la probabilitat\n",
    "    '''\n",
    "    sigmoid = f(x) = 1/(1+e^-x)\n",
    "    '''\n",
    "    #Model de localització de coordenades\n",
    "    f2 = GlobalMaxPooling2D()(vgg)\n",
    "    regress1 = Dense(2048, activation='relu')(f2)\n",
    "    regress2 = Dense(4, activation='sigmoid')(regress1)\n",
    "    \n",
    "    detector = Model(inputs=input_layer, outputs=[class2, regress2])\n",
    "    return detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97226aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.as_numpy_iterator().next()[1]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b84e6fb2",
   "metadata": {},
   "source": [
    "### 3.1 Prova de la xarxa neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dbda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3785c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "detector.summary()\n",
    "'''\n",
    "Aquest fragment dona una descripció resumida de la xarxa que acabem de construir,\n",
    "inclou el nombre de capes, el nombre de paràmetres que ha après durant un entrenament i \n",
    "la forma de les dades que passen entre les capes.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49668c86",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = train.as_numpy_iterator().next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f4beb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "715392aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, coords = detector.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586ead66",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes, coords"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6e82e086",
   "metadata": {},
   "source": [
    "### 3.2 Definir pèrdues i optimitzadors\n",
    "Els optimitzadors són algorismes que s’utilitzen per ajustar els pesos d’una xarxa neuronal durant l’entrenament. Els optimitzadors són responsables de minimitzar la funció de pèrdua de la xarxa neuronal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a95066a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.0001) #li introduïm el decay que hem calculat a l'optimitzador\n",
    "\n",
    "'''\n",
    "En el context de les xarxes neuronals, un optimitzador és un algorisme\n",
    "que ajuda a ajustar els paràmetres de la xarxa per aconseguir una millor precisió.\n",
    "L'optimitzador Adam és un exemple d'això i ajuda a l'optimitzador a convergir més ràpidament\n",
    "i amb més precisió.\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "400ff5f5",
   "metadata": {},
   "source": [
    "La funció té dos components: la pèrdua de localització i la pèrdua de classificació.\n",
    "La pèrdua de localització mesura la diferència entre les coordenades dels quadres delimitadors \n",
    "predits i les coordenades dels quadres delimitadors reals. La pèrdua de classificació mesura la\n",
    "diferència entre les probabilitats de classe predites i les probabilitats de classe reals. \n",
    "En aquesta funció, només es calcula la pèrdua de localització.\n",
    "\n",
    "La funció té com a entrada dos tensors: y_true i yhat. \n",
    "y_true conté les coordenades dels quadres delimitadors reals i\n",
    "les probabilitats de classe reals per a cada objecte en la imatge d’entrada.\n",
    "yhat conté les coordenades dels quadres delimitadors predits i les\n",
    "probabilitats de classe predites per a cada objecte en la imatge d’entrada.\n",
    "\n",
    "La funció calcula la pèrdua de localització sumant el quadrat de la diferència\n",
    "entre les coordenades dels quadres delimitadors reals i les coordenades dels quadres\n",
    "delimitadors predits. A continuació, calcula la diferència entre l’amplada i l’alçada\n",
    "dels quadres delimitadors reals i els quadres delimitadors predits i suma els quadrats\n",
    "d’aquestes diferències. Finalment, retorna la suma de les dues pèrdues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0159efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def localization_loss(y_true, yhat):#primer valor: coordenades reals, segon valor: coordenades previstes     \n",
    "    delta_coord = tf.reduce_sum(tf.square(y_true[:,:2] - yhat[:,:2])) #diferència dels dos primers valors de cada fila de la matriu\n",
    "                  \n",
    "    h_true = y_true[:,3] - y_true[:,1] #quarta columna d'una matriu - segona columna\n",
    "    w_true = y_true[:,2] - y_true[:,0] #tercera columna - primera\n",
    "\n",
    "    h_pred = yhat[:,3] - yhat[:,1] \n",
    "    w_pred = yhat[:,2] - yhat[:,0] \n",
    "    '''\n",
    "    delta_size = suma dels quadrats de les diferències entre les dimensions originals \n",
    "    i les dimensions reconstruïdes de l'imatge.\n",
    "    '''\n",
    "    delta_size = tf.reduce_sum(tf.square(w_true - w_pred) + tf.square(h_true-h_pred))\n",
    "    return delta_coord + delta_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72140c33",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss = tf.keras.losses.BinaryCrossentropy() #model que fa una classificació binaria \n",
    "regressloss = localization_loss #model que acabem de crear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9d2d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test, en les 2 cel·les inferiors s'hauria d'obtenir : <tf.Tensor: shape=(), dtype=float32, numpy=n>\n",
    "regressloss(y[1], coords) #y[0] ==> 0 o 1 (hi ha maduixa o no) , y[1] ==> coords (tot del batch sencer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eb81dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "classloss(y[0], classes) #numpy ==> probabilitat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae7b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "localization_loss(y[1],coords)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
