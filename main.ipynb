{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33e0455a",
   "metadata": {},
   "source": [
    "# 1. Recol·lecció i tractament de dades"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa979ccf",
   "metadata": {},
   "source": [
    " * 1.1 Executem la llibreria LabelMe, que manualment ens permetrà obtenir unes coordenades que marquin la àrea del objecte que volem detectar. Aquesta llibreria ens retornarà un arxiu .json amb els valors numèrics dels punts marcats. Amb aquests valors, la xarxa neuronal serà capaç d'entrenar-se. Haurem de crear una carpeta que anomenarem \"labels\" on hi aniran aquestes \"etiquetes\" en format .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme #execució de la llibreria labelme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23d6376c",
   "metadata": {},
   "source": [
    "# 2. Creació de la base de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42b8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importació de llibreries necessàries\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ac200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limitació de la memòria GPU \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce224428",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges = tf.data.Dataset.list_files('data\\\\images\\\\*.png') # introduïm les imatges a la base de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_imatge(imatge): #funció per a carregar imatges\n",
    "    byte_img = tf.io.read_file(imatge)\n",
    "    img = tf.io.decode_png(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges = imatges.map(carregar_imatge) # executem la funció per carregar les imatges en la base de dades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges.as_numpy_iterator().next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantImatgesDividir(dir_carpeta):\n",
    "    num_elements = len(os.listdir(dir_carpeta))\n",
    "    n_entrenar = round(num_elements*0.7) # 70% de les imatges per entrenar\n",
    "    n_provar = round(num_elements*0.15) # 15% de les imatges per provar\n",
    "    n_validar = num_elements - (n_entrenar + n_provar) # 15% de les imatges per validar\n",
    "    print(f\"{n_entrenar} --> 'train' \\n {n_provar} --> 'test' \\n {n_validar} --> 'val'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantImatgesDividir('T:\\REP\\deteccio_prova\\data\\images') # s'han de dividir manualment les imatges (intentant que sigui aleatori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dce6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mou les els labels a les seves respectives carpetes\n",
    "for carpeta in ['train','test','val']:\n",
    "    for arxiu in os.listdir(os.path.join('data', carpeta, 'images')): #per cada arxiu en cada carpeta\n",
    "        nom_arxiu = arxiu.split('.')[0]+'.json' #extreu el nom de l'arxiu\n",
    "        dir_existent = os.path.join('data','labels', nom_arxiu)#crea possible direcció\n",
    "        if os.path.exists(dir_existent): #si la possible direcció existeix, desplaça l'arxiu .json corresponent\n",
    "            nova_dir = os.path.join('data',carpeta,'labels',nom_arxiu)\n",
    "            os.replace(dir_existent, nova_dir)#canviem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70389c",
   "metadata": {},
   "source": [
    "### 2.1 Augmentem la quantitat de dades amb la llibreria Albumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071c1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93969970",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=1024, height=1024),\n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', #format de coords que volem (buscar docs)\n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train','test','val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [1024,1024,1024,1024]))\n",
    "            # ^^^ carregar imatges i json ^^^\n",
    "\n",
    "        try: \n",
    "            for x in range(60):# quantitat d'imatges que surten d'una imatge base\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['Maduixa'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'),augmented['image'])\n",
    "                \n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "                    '''\n",
    "                     La variable “annotation” és un diccionari que conté informació sobre la imatge i \n",
    "                     la seva anotació. Si el fitxer d’anotació existeix, el codi afegeix la caixa delimitadora\n",
    "                     i la classe corresponent a l’objecte detectat a l’estructura “annotation”. \n",
    "                     Si el fitxer d’anotació no existeix, el codi assigna una caixa delimitadora i \n",
    "                     una classe buida a l’estructura “annotation”.\n",
    "                    '''\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cf0c55a",
   "metadata": {},
   "source": [
    "### 2.2 Incloure imatges creades amb Albumentations a la Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16bf99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Obrim les carpetes amb les img a manipular i les carreguem\n",
    "train_images = tf.data.Dataset.list_files('aug_data\\\\train\\\\images\\\\*.jpg',shuffle=False)\n",
    "train_images = train_images.map(carregar_imatge)\n",
    "#Es fa resize de les img i també baixem l'escala de la imatge a 1\n",
    "train_images = train_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "train_images = train_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05456564",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = tf.data.Dataset.list_files('aug_data\\\\test\\\\images\\\\*.jpg', shuffle=False)\n",
    "test_images = test_images.map(carregar_imatge)\n",
    "test_images = test_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "test_images = test_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167107c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_images = tf.data.Dataset.list_files('aug_data\\\\val\\\\images\\\\*.jpg', shuffle=False)\n",
    "val_images = val_images.map(carregar_imatge)\n",
    "val_images = val_images.map(lambda x: tf.image.resize(x, (250,250)))\n",
    "val_images = val_images.map(lambda x: x/255)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0900d8c7",
   "metadata": {},
   "source": [
    "### 2.3 Carregar Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f31855c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#funció que carrega els labels\n",
    "def carregar_labels(x):\n",
    "    with open(x.numpy(), 'r', encoding='utf-8') as f:\n",
    "        label = json.load(f)\n",
    "    return [label['class']],label['bbox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f279ef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = tf.data.Dataset.list_files('aug_data\\\\train\\\\labels\\\\*.json', shuffle=False)\n",
    "train_labels = train_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))#tf_py_function(funció, paràmetres, tipus de retorn) \n",
    "#obre els labels i els aplica la funció carregar_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fbc102b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = tf.data.Dataset.list_files('aug_data\\\\test\\\\labels\\\\*.json', shuffle=False)\n",
    "test_labels = test_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a532244b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = tf.data.Dataset.list_files('aug_data\\\\val\\\\labels\\\\*.json', shuffle=False)\n",
    "val_labels = val_labels.map(lambda x: tf.py_function(carregar_labels, [x], [tf.uint8, tf.float16]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c9566b",
   "metadata": {},
   "source": [
    "### 2.4 Combinar labels i imatges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00975b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cal comprovar quantes imatges hi ha en cada carpeta\n",
    "print(\"Train: \" + str(len(train_labels)) + \", Test: \" + str(len(test_labels)) + \", Val: \" + str(len(val_labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea1c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = tf.data.Dataset.zip((train_images, train_labels)) #mètode que junta les imatges amb els labels\n",
    "train = train.shuffle(2000) #posar el número que hi ha apoximat cap amunt, en aquest cas 2000\n",
    "train = train.batch(8)#crear lots de 8\n",
    "train = train.prefetch(4)#redueix la capacitat de procesar per evitar errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ba0be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = tf.data.Dataset.zip((test_images, test_labels))\n",
    "test = test.shuffle(500)\n",
    "test = test.batch(8)\n",
    "test = test.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "910bd91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = tf.data.Dataset.zip((val_images, val_labels))\n",
    "val = val.shuffle(500)\n",
    "val = val.batch(8)\n",
    "val = val.prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18989ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.as_numpy_iterator().next()[1]\n",
    "'''\n",
    "Amb això visualitzem la manera en què hem codificat i guardat les imatges;\n",
    "Obtindrem això:\n",
    "(array([[n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n],\n",
    "        [n]], dtype=uint8),\n",
    " array([[n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n],\n",
    "        [n , n , n , n]], dtype=float16))\n",
    "\n",
    "la primera columna ens indica la classe de la imatge, és a dir, l'objecte que hi ha a la imatge\n",
    "la segona columna ens indica la bounding box de la imatge, és a dir, la posició de l'objecte a la imatge\n",
    "\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
