{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "33e0455a",
   "metadata": {},
   "source": [
    "# 1. Recol·lecció i tractament de dades"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aa979ccf",
   "metadata": {},
   "source": [
    " * 1.1 Executem la llibreria LabelMe, que manualment ens permetrà obtenir unes coordenades que marquin la àrea del objecte que volem detectar. Aquesta llibreria ens retornarà un arxiu .json amb els valors numèrics dels punts marcats. Amb aquests valors, la xarxa neuronal serà capaç d'entrenar-se. Haurem de crear una carpeta que anomenarem \"labels\" on hi aniran aquestes \"etiquetes\" en format .json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaed57d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelme #execució de la llibreria labelme"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "23d6376c",
   "metadata": {},
   "source": [
    "# 2. Creació de la base de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b42b8df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importació de llibreries necessàries\n",
    "import tensorflow as tf\n",
    "import json\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b7ac200",
   "metadata": {},
   "outputs": [],
   "source": [
    "#limitació de la memòria GPU \n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "for gpu in gpus: \n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce224428",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges = tf.data.Dataset.list_files('data\\\\images\\\\*.png') # introduïm les imatges a la base de dades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3a5584",
   "metadata": {},
   "outputs": [],
   "source": [
    "def carregar_imatge(imatge): #funció per a carregar imatges\n",
    "    byte_img = tf.io.read_file(imatge)\n",
    "    img = tf.io.decode_png(byte_img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7a78f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges = imatges.map(carregar_imatge) # executem la funció per carregar les imatges en la base de dades "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dad48be",
   "metadata": {},
   "outputs": [],
   "source": [
    "imatges.as_numpy_iterator().next() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa93ae8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantImatgesDividir(dir_carpeta):\n",
    "    num_elements = len(os.listdir(dir_carpeta))\n",
    "    n_entrenar = round(num_elements*0.7) # 70% de les imatges per entrenar\n",
    "    n_provar = round(num_elements*0.15) # 15% de les imatges per provar\n",
    "    n_validar = num_elements - (n_entrenar + n_provar) # 15% de les imatges per validar\n",
    "    print(f\"{n_entrenar} --> 'train' \\n {n_provar} --> 'test' \\n {n_validar} --> 'val'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8643289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantImatgesDividir('T:\\REP\\deteccio_prova\\data\\images') # s'han de dividir manualment les imatges (intentant que sigui aleatori)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dce6b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mou les els labels a les seves respectives carpetes\n",
    "for carpeta in ['train','test','val']:\n",
    "    for arxiu in os.listdir(os.path.join('data', carpeta, 'images')): #per cada arxiu en cada carpeta\n",
    "        nom_arxiu = arxiu.split('.')[0]+'.json' #extreu el nom de l'arxiu\n",
    "        dir_existent = os.path.join('data','labels', nom_arxiu)#crea possible direcció\n",
    "        if os.path.exists(dir_existent): #si la possible direcció existeix, desplaça l'arxiu .json corresponent\n",
    "            nova_dir = os.path.join('data',carpeta,'labels',nom_arxiu)\n",
    "            os.replace(dir_existent, nova_dir)#canviem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f70389c",
   "metadata": {},
   "source": [
    "### 2.1 Augmentem la quantitat de dades amb la llibreria Albumentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "071c1384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import albumentations as alb\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93969970",
   "metadata": {},
   "outputs": [],
   "source": [
    "augmentor = alb.Compose([alb.RandomCrop(width=1024, height=1024),\n",
    "                         alb.HorizontalFlip(p=0.5), \n",
    "                         alb.RandomBrightnessContrast(p=0.2),\n",
    "                         alb.RandomGamma(p=0.2), \n",
    "                         alb.RGBShift(p=0.2), \n",
    "                         alb.VerticalFlip(p=0.5)], \n",
    "                       bbox_params=alb.BboxParams(format='albumentations', #format de coords que volem (buscar docs)\n",
    "                                                  label_fields=['class_labels']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a36e346",
   "metadata": {},
   "outputs": [],
   "source": [
    "for partition in ['train','test','val']: \n",
    "    for image in os.listdir(os.path.join('data', partition, 'images')):\n",
    "        img = cv2.imread(os.path.join('data', partition, 'images', image))\n",
    "\n",
    "        coords = [0,0,0.00001,0.00001]\n",
    "        label_path = os.path.join('data', partition, 'labels', f'{image.split(\".\")[0]}.json')\n",
    "        if os.path.exists(label_path):\n",
    "            with open(label_path, 'r') as f:\n",
    "                label = json.load(f)\n",
    "\n",
    "            coords[0] = label['shapes'][0]['points'][0][0]\n",
    "            coords[1] = label['shapes'][0]['points'][0][1]\n",
    "            coords[2] = label['shapes'][0]['points'][1][0]\n",
    "            coords[3] = label['shapes'][0]['points'][1][1]\n",
    "            coords = list(np.divide(coords, [1024,1024,1024,1024]))\n",
    "            # ^^^ carregar imatges i json ^^^\n",
    "\n",
    "        try: \n",
    "            for x in range(60):# quantitat d'imatges que surten d'una imatge base\n",
    "                augmented = augmentor(image=img, bboxes=[coords], class_labels=['Maduixa'])\n",
    "                cv2.imwrite(os.path.join('aug_data', partition, 'images', f'{image.split(\".\")[0]}.{x}.jpg'),augmented['image'])\n",
    "                \n",
    "                annotation = {}\n",
    "                annotation['image'] = image\n",
    "\n",
    "                if os.path.exists(label_path):\n",
    "                    if len(augmented['bboxes']) == 0: \n",
    "                        annotation['bbox'] = [0,0,0,0]\n",
    "                        annotation['class'] = 0 \n",
    "                    else: \n",
    "                        annotation['bbox'] = augmented['bboxes'][0]\n",
    "                        annotation['class'] = 1\n",
    "                else: \n",
    "                    annotation['bbox'] = [0,0,0,0]\n",
    "                    annotation['class'] = 0 \n",
    "                    '''\n",
    "                     La variable “annotation” és un diccionari que conté informació sobre la imatge i \n",
    "                     la seva anotació. Si el fitxer d’anotació existeix, el codi afegeix la caixa delimitadora\n",
    "                     i la classe corresponent a l’objecte detectat a l’estructura “annotation”. \n",
    "                     Si el fitxer d’anotació no existeix, el codi assigna una caixa delimitadora i \n",
    "                     una classe buida a l’estructura “annotation”.\n",
    "                    '''\n",
    "                with open(os.path.join('aug_data', partition, 'labels', f'{image.split(\".\")[0]}.{x}.json'), 'w') as f:\n",
    "                    json.dump(annotation, f)\n",
    "\n",
    "        except Exception as e:\n",
    "            print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
